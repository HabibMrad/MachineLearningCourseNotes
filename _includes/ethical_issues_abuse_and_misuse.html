<h2>Abuse and Misuse</h2>

<p>Throughout the history of our species, people have invented a large variety of useful tools that have bettered our lives. But with each tool, from the spear to the computer, there comes the potential for abuse or misuse.</p>
<p>Some researchers demonstrated ways to “trick” machine learning algorithms to label images as gibbons. <a target="_blank" href="https://arxiv.org/abs/1312.6199">By inserting some “adversarial noise” it’s possible to perturb the algorithms to assign an incorrect label to an image.</a></p>
<p><img src="http://yourshot.nationalgeographic.com/u/ss/fQYSUbVfts-T7pS2VP2wnKyN8wxywmXtY0-Fwsgxpz-7KQoPM7C9KUxz6eybQ_f4a8jMQcqBL_pp6G-7Kndb/" alt="" width="419" height="391"></p>
<p><em>This is a gibbon.</em></p>
<p>This could potentially be used to deliberately harm others. For instance, might it be possible to somehow alter the clothing of a person so that self-driving cars do not identify them as a pedestrian? This is just one example of intentional misuse of technologies. How do we build safeguards around machine learning technologies that make it harder for them to be abused?</p>
<p>What are examples of models that we should be most worried about attackers tricking? There's a variety of issues that may come up due to how an organization uses, abuses or misuses the data and algorithms in machine learning.</p>
<p>Google put out a list of principles they intend to follow in building their software. (See reading below). Axon, a US company that develops weapons products for law enforcement and civilians (including tasers) arranged an AI Ethics board (link below).</p>
<p></p>
<h3>Readings</h3>
<p><a target="_blank" href="https://www.axon.com/info/ai-ethics">Axon AI Ethics Board</a></p>
<p><a target="_blank" href="https://www.blog.google/technology/ai/ai-principles/">Google's AI Principles</a> and <a target="_blank" href="https://www.eff.org/deeplinks/2018/06/how-good-are-googles-new-ai-ethics-principles">concerns about Google's AI Principles</a></p>
<p><a target="_blank" href="https://www.theguardian.com/technology/2017/mar/13/artificial-intelligence-ai-abuses-fascism-donald-trump">Artificial Intelligence Is Ripe for Abuse, Tech Researcher Warns</a> - The Guardian</p>
