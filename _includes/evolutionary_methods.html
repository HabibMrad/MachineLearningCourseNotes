<h2>Evolutionary Methods</h2>
<p>As the name might suggest, <strong>evolutionary methods</strong> are inspired by the mechanisms of biological evolution.</p>
<p>Unlike with reinforcement learning, where we are trying to find the best policy by taking steps in the best direction from where we are, an evolutionary algorithm tries out several completely different policies. These policies make up the <strong>population</strong> for the current <strong>generation</strong>.</p>
<p>For each generation, we interact with the environment using the policy, and select the policies that work best. These chosen polices, plus combinations and/or mutations of them become the population of the next generation of policies. This new generation is tried out, and the cycle repeats. As the model goes through more generations, the populations get better and better at the task.</p>
<p><a target="_blank" href="https://eng.uber.com/deep-neuroevolution/">Uber AI has published a number of papers and some example code showing evolutionary algorithms that can outperform other reinforcement learning techniques on certain tasks.</a> They obtained good results through very simple mechanisms, but they also tried somewhat more sophisticated methods as well. For instance, their <strong>safe mutations</strong> pay attention to how much the change in each parameter affects the outcome, making smaller changes to parameters that have larger effects.</p>
<p>This <a target="_blank" href="https://becominghuman.ai/genetic-algorithm-for-reinforcement-learning-a38a5612c4dc">tutorial</a> gives an example of using evolutionary methods to solve a problem in OpenAI's gym of reinforcement learning problems.</p>
