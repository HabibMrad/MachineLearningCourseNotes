<h2>Parameters and Hyperparameters</h2>

<p>In many of our machine learning algorithms, we are attempting to fit <strong>parameters</strong> of our model: the coefficients and slope in linear or logistic regression, the probabilities in Naive Bayes, or the coordinates of the surface in support vector machines. These are numbers that we want to learn from the data.</p>

<p>However, there are other choices that we have to make ahead of time, that do not change based on the data, and these are called <strong>hyperparameters</strong>. For instance, we have to tell our regression ahead of time what degree of polynomial we want to go up to. Similarly, we have to assume some distribution our data are drawn from for Naive Bayes. And we have to decide what fraction of features or inputs we will use for each tree in our Random Forest.There are various methods for choosing <strong>hyperparameters</strong>, and we'll be talking about this more as we look at more algorithms.</p>
