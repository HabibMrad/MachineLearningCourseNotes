<h2>Probabilistic Programming</h2>
<p>Whenever we are training a model, we need to pay careful attention to how we input our training data. Is it numerical or categorical? Does it have some sort of structure, like audio data or an image? If we have some knowledge about how the inputs relate to the outputs, we choose a model that can capture that type of relationship, or something close to it. Typically, all of our inputs are treated the same, meaning they either have to have the same types of relationships to the outputs or the model needs to discover the relationship in the course of training. But what if we already some knowledge about this? How could we let the model know that, to give it a head start in searching for a good fit to the training data?</p>
<p><strong>Probabilistic programming</strong> allows us to put more information about the relationships between our inputs and outputs into our model. When using this type of model, we assume that our data were generated by drawing samples from some combination of <strong>probability distributions</strong> (for instance, <a target="_blank" href="https://en.wikipedia.org/wiki/Bernoulli_distribution">bernoulli</a>, <a target="_blank" href="https://en.wikipedia.org/wiki/Binomial_distribution">binomial</a>, <a target="_blank" href="https://en.wikipedia.org/wiki/Normal_distribution">normal/gaussian</a>, <a target="_blank" href="https://en.wikipedia.org/wiki/Gamma_distribution">gamma</a>, <a target="_blank" href="https://en.wikipedia.org/wiki/Poisson_distribution">poisson</a>, <a target="_blank" href="https://en.wikipedia.org/wiki/Dirichlet_distribution">dirichlet</a>). What we want to know are what the <strong>parameters</strong> of the distributions were (for instance, if it is a normal distribution, we want to know the mean and standard deviation). With our training data, we perform <strong>inference</strong> to estimate the parameters.</p>
<p>For instance, let's think about our favorite iris dataset. Say we talk to a botanist and she tells us that each of the four characteristics that were measured follow roughly a normal distribution across flowers of the same species. We could act as though the iris dataset were generated using twelve different normal distributions, one for each of the four measurements for each of the three different species. Using our training data, we could figure out likely values for the mean and standard deviation of each of these normal distributions. Now, when we want to predict the species of an unknown iris, we look at which of the species would be most likely to generate its set of four values. (Note: the model described above is a bit oversimplified from reality, because it assumes that the four characteristics are generated independently for each flower, whereas perhaps a flower with a larger sepal width for its species is more likely to also have a larger sepal length. We could make the generating model more sophisticated to take this into account, if we wanted.)</p>
<p>One of the great benefits to a probabilistic model once it is trained is that we can perform a wider variety of tasks compared to most models: we can ask it to predict not only the output given inputs but also missing inputs given other inputs or the output, and we can use it like a <a class="jump-to-section" href="#generative-models">Generative Model</a>. So, for instance, say one of the researchers mistakely forgot to record one of the measurements for an iris. With the same model that predicts the species of iris, we could instead predict that measurement. Or we could generate a reasonable set of all four measurements for a particular species.</p>
<p>Two main drawbacks of probabilistic programming are that inference often takes a very long time and that there is no sure way of knowing when you have trained enough. You may recognize these drawbacks as problems that neural networks also have. For probabilistic programming, the problem of how long things take is worse than for neural networks: the slow speed of training is one of the biggest reasons this is not in more widespread use. However, when to stop is less of a problem for probabilistic programming, because more training does not lead to more overfitting in the same way that it can with neural networks.</p>
<h3>Training</h3>
<p>Like many of the other machine learning algorithms we have studied, the training process for probabilistic models is considerably more complicated than the forward pass through the model. For any single probability distribution, there is usually a closed form solution for the estimate of a parameter given samples from that distribution, but as soon as you get into joint distributions, even of just two probability distributions, there is often no way to isolate a single parameter. Since our models will usually involve many distributions, there is no way to solve for our parameters directly.</p>
<p>Instead, we use techniques similar to the gradient descent/backpropagation techniques we saw with neural networks: we start out with our <strong>priors</strong> for the parameters, which can be random guesses or good guesses, if those exist. We repeatedly change the parameters a bit and see if this change puts us closer to fitting our data. This technique is called <strong>markov chain monte carlo</strong> or <strong>MCMC</strong>. You can find an intuitive-ish explanation <a target="_blank" href="https://towardsdatascience.com/a-zero-math-introduction-to-markov-chain-monte-carlo-methods-dcba889e0c50">here</a>. As the MCMC sampling continues to run, it will be <a target="_blank" href="https://www.johndcook.com/blog/2016/01/25/mcmc-burn-in/">more and more likely to be drawing from areas that have high probability given the data</a>, and thus the samples will give a probability distribution for the values of the parameters we wanted to find.</p>
<h3>Examples in Pystan</h3>
<ul>
    <li><a target="_blank" href="https://pystan.readthedocs.io/en/latest/optimizing.html">An example of inferring the mean value of data assuming a normal distribution</a> This is not practically useful, but it illustrates how to set up a model</li>
    <li><a target="_blank" href="https://mc-stan.org/users/documentation/case-studies.html">Stan case studies</a> This page contains example code for a number of different probabalistic analyses, some on real datasets. Search for "pystan" unless you want to learn (or know how) to read the R language.</li>
</ul>
<p>To run these examples, you will need to install Pystan:</p>
<pre>python3 -m pip install pystan</pre>
