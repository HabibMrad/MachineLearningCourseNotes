{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Dataset Processing\n",
    "#### Carl Shan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook will share more details about how to process your data. Data processing is like preparing the ingredients before cooking; if you prepare them poorly (e.g., leave things half-peeled and dirty) , the meal will taste poor no matter how skillful a chef you are. \n",
    "\n",
    "It's similarly true in machine learning. Dataset processing can be one of the most important things you can do to get your model to perform well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introducing some helpful \"magic\" Jupyter commands\n",
    "? - this will bring up the documentation of a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the [student performance data](http://archive.ics.uci.edu/ml/machine-learning-databases/00320/) and change the path below to wherever you put the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data = pd.read_csv('../data/student/student-mat.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Categorical Values to Numerical Ones\n",
    "\n",
    "Looking at the data above, we want to convert a number of the columns from categorical to numerical. Most machine learning models deal with numbers and don't know how to model data that is in text form. As a result we need to learn how to do things such as e.g., convert the values in the `school` column to numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, let's see what values there are in the `school` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows a list of unique values and how many times they appear\n",
    "student_data['school'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting values in the school column to text\n",
    "# We are going to define a function that takes a single value and apply it to all the values\n",
    "def convert_school(row):\n",
    "    if row == 'GP':\n",
    "        return 0\n",
    "    elif row == 'MS':\n",
    "        return 1\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avoid for loops\n",
    "Normally, we might write a for loop like the one below. But this is really slow when using Pandas. _Don't write loops like this_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a slow way of using the above function\n",
    "%time\n",
    "converted_school = []\n",
    "\n",
    "for row in student_data['school']:\n",
    "    new_value = convert_school(row)\n",
    "    converted_school.append(new_value)\n",
    "converted_school"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use apply instead of for loops\n",
    "This will do the same thing as the for loop above, but _much_ faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "converted_school = student_data['school'].apply(convert_school)\n",
    "converted_school"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using sklearn's built-in preprocessing module, we can do the same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_school = preprocessing.LabelEncoder()\n",
    "transformed_school = enc_school.fit_transform(student_data['school'])\n",
    "transformed_school"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can also use one-hot encoding if we have more than two values. We still need to encode it first, as we did above.\n",
    "See example at https://stackoverflow.com/a/43589167/2159992"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_mjob = preprocessing.LabelEncoder()\n",
    "encoded_mjob = enc_mjob.fit_transform(student_data['Mjob'])\n",
    "encoded_mjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_mjob = preprocessing.OneHotEncoder(sparse=False)\n",
    "transformed_mjob = onehot_mjob.fit_transform(encoded_mjob.reshape(-1,1))\n",
    "transformed_mjob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've fitted the label encoder and one-hot encoder, we can use them to transform more values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_mjob.transform(enc_mjob.transform(['other', 'health']).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What if we want to apply a transform that looks at multiple values in the row?\n",
    "For instance, what if we want to create a new column with a 1 if both parents have the highest level of education measured?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medu_index = student_data.columns.get_loc('Medu')\n",
    "fedu_index = student_data.columns.get_loc('Fedu')\n",
    "\n",
    "def both_parents_edu(row):\n",
    "    if row[medu_index] > 3 and row[fedu_index] >= 4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# axis 1 means that we will apply the function to each row\n",
    "student_data['parents_high_edu'] = student_data.apply(both_parents_edu, axis=1)\n",
    "student_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with Null values\n",
    "To show you how to deal with null values, I'm going to make some simulated data of students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = np.random.choice(range(1, 13), 100) # chooses 100 random numbers between 1 - 12\n",
    "num_friends_or_none = list(range(0, 20)) + [None] * 5\n",
    "num_friends = np.random.choice(num_friends_or_none, 100)\n",
    "new_data = pd.DataFrame(data={'Grade': grades, '# Friends': num_friends})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One way to deal with null values is to drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['# Friends'].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can also drop any rows with nulls from the entire table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or we can replace the null values with an average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_friends = new_data['# Friends'].mean()\n",
    "new_data['# Friends'].fillna(average_friends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['# Friends'] = new_data['# Friends'].fillna(average_friends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What if instead of null values, there is something else that stands for missing values?\n",
    "Try the replace function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = np.random.choice(range(1, 13), 100) # chooses 100 random numbers between 1 - 12\n",
    "num_friends_or_none = list(range(0, 20)) + [\"Unknown\"] * 5\n",
    "num_friends = np.random.choice(num_friends_or_none, 100)\n",
    "unknown_data = pd.DataFrame(data={'Grade': grades, '# Friends': num_friends})\n",
    "unknown_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_data.replace(\"Unknown\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's learn how to standardize data\n",
    "By that I mean to transform our data so that it has a mean of 0 and a standard deviation of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit_transform(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What if we would like to split up columns?\n",
    "We can use apply here, as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = np.random.choice(range(1, 13), 100) # chooses 100 random numbers between 1 - 12\n",
    "grades_and_ages = ['{grade} - {age}'.format(grade=grade, age=grade+6) for grade in grades]\n",
    "num_friends_or_none = list(range(0, 20)) + [\"Unknown\"] * 5\n",
    "num_friends = np.random.choice(num_friends_or_none, 100)\n",
    "combined_data = pd.DataFrame(data={'Grade and Age': grades_and_ages, '# Friends': num_friends})\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_age_index = combined_data.columns.get_loc('Grade and Age')\n",
    "friends_index = combined_data.columns.get_loc('# Friends')\n",
    "\n",
    "def split_grade_and_age(row):\n",
    "    friends = row[friends_index]\n",
    "    grade_age = row[grade_age_index].split(\" - \")\n",
    "    grade = int(grade_age[0])\n",
    "    age = int(grade_age[1])\n",
    "    return pd.Series({'Grade': grade, 'Age': age, '# Friends': friends})\n",
    "\n",
    "# axis 1 means we will get the entire row at once\n",
    "combined_data.apply(split_grade_and_age, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
